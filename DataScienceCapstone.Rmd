---
title: "MovieLens Project"
author: "Richa Gautam"
date: "4/11/2020"
geometry: margin=1in
output: pdf_document
---
#Utilizing the Movielens Database to Predict Movie Preferences


```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(fig.width=8, fig.height=6, fig.align = "center") 

################################
# Create edx set, validation set
################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(Metrics)) install.packages("Metrics", repos = "http://cran.us.r-project.org")
if(!require(scales)) install.packages("scales", repos = "http://cran.us.r-project.org")
if(!require(BBmisc)) install.packages("BBmisc", repos = "http://cran.us.r-project.org")
if(!require(corrplot)) install.packages("corrplot", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(psych)) install.packages("psych", repos = "http://cran.us.r-project.org")
if(!require(Hmisc)) install.packages("Hmisc", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(data.table)
library(Metrics)
library(scales)
library(BBmisc)
library(corrplot)
library(lubridate)
library(psych)
library(Hmisc)

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1)
# if using R 3.5 or earlier, use `set.seed(1, sample.kind="Rounding")` instead
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)

```
##Introduction

Why do we watch the movies we do? In the era of binge-watching, the answer to this question has largely been "because we watched a similar movie before." Streaming services' algorithms curate our dashboard to recommend movies that they find most likely to appeal to us. This appeal could be based on your bias towards certain genres, or an era, or an actor or a director. I for example will watch anything with Andy Samberg in it. My partner on the other hand is a fan of bad horror movies.

We can therefore hypothesize that people tend to like things based on certain foundational preferences. This insight is hugely useful when trying to predict human behavior. Imagine you are inviting friends over for a movie. What movie should you suggest that will please most of the crowd?

##Overview

In this report, I will outline the steps taken to create a recommendation system given the genre, year, and `r nrow(edx)` user ratings of `r edx %>% group_by(movieId) %>% count() %>% nrow()` unique movies by `r edx %>% group_by(userId) %>% count() %>% nrow()` unique users from the Movielens database.

##Executive Summary

I hypothesized that this problem will require a regression machine learning algorithm, as the dependent variable (variable being predicted; ratings) is continuous, and the independent variables (variable being used to predict; genre, and users, movies) are categorical. Using the xxx machine learning method, I was able to predict movie ratings with xx% accuracy. The root mean squared error (RMSE) was xx. 

##Methods

The dataset was obtained from http://grouplens.org using code provided by the Data Science Capstone course being taught by Harvard Extension school. The final dataset had `r nrow(edx)` observations of `r ncol(edx)` variables - userId, movieId, rating, timestamp, title, and genres.

Of the variables, our independent variables (IVs) were "genres," a character vector, "year," which was extracted from the "title" column, and "userId," an integer vector. Our dependent variable (DV) was "rating," a numeric vector. 

###Pre-processing

The code provided by edx led to a dataset without any incomplete rows, and another validation dataset with 10% of the full dataset's observations. I began with the full dataset.

The "genres" column could contain one or multiple genres, separated by "|". So my first task was to separate the responses in that column. However, working with dataframes is more time consuming, so I decided to convert the separated genre data into a matrix.

```{r preprocessing, echo=FALSE}
###Separate combined genres###

edx = edx %>% mutate(Action = ifelse(grepl("Action", genres), 1, 0),
                     Adventure = ifelse(grepl("Adventure", genres), 1, 0),
                     Animation = ifelse(grepl("Animation", genres), 1, 0),
                     Children = ifelse(grepl("Children", genres), 1, 0),
                     Comedy = ifelse(grepl("Comedy", genres), 1, 0),
                     Crime = ifelse(grepl("Crime", genres), 1, 0),
                     Documentary = ifelse(grepl("Documentary", genres), 1, 0),
                     Drama = ifelse(grepl("Drama", genres), 1, 0),
                     Fantasy = ifelse(grepl("Fantasy", genres), 1, 0),
                     Film_noir = ifelse(grepl("Film-Noir", genres), 1, 0),
                     Horror = ifelse(grepl("Horror", genres), 1, 0),
                     Musical = ifelse(grepl("Musical", genres), 1, 0),
                     Mystery = ifelse(grepl("Mystery", genres), 1, 0),
                     Romance = ifelse(grepl("Romance", genres), 1, 0),
                     Sci_Fi = ifelse(grepl("Sci-Fi", genres), 1, 0),
                     Thriller = ifelse(grepl("Thriller", genres), 1, 0),
                     War = ifelse(grepl("War", genres), 1, 0),
                     Western = ifelse(grepl("Western", genres), 1, 0))

#Create function to pull out characters from the right end of a string
substrR <- function(x, n){
  substr(x, nchar(x)-n+1, nchar(x))
}

edx = edx %>% mutate(year = substr(substrR(substrR(edx$title, 6),5),1,4))

edx$year = as.numeric(edx$year)

edx <- edx %>%
  mutate(rating_datetime = year(as_datetime(timestamp)))
```

As you can see, the genre data from the large dataset has been dummy-coded:
```{r edx, echo=FALSE}
head(edx)
```

###Preliminary Predictions

####User Effects

Movie ratings will be impacted by the user, as users have different tastes and some users are likely to rate movies more highly on average than others. Table 1 shows the mean rating and standard deviation for the first 6 userIds.
```{r usereffects1, echo=FALSE}
head(edx %>% group_by(userId) %>% summarise(Users_Rated=n(), Mean_Rating=mean(rating), SD_Rating=sd(rating))
)
```
Table 1: Mean rating and standard deviation for the first 6 userIds.

Figure 1 visualizes the number of ratings for the first 100 userIds.
```{r usereffects2, echo=FALSE, fig.align = "center"}
user_counts = edx %>% group_by(userId) %>% summarise(Movies_Rated=n(), Mean_Rating=mean(rating), Standard_Deviation = sd(rating))
user_counts[1:100,] %>% 
  ggplot(aes(x=userId, y=Movies_Rated)) + 
  geom_bar(stat="identity") + 
  labs(title = "Number of Movies Rated by Each User")+
  ylab("Number of Movies Rated")
```
Figure 1: Number of Movies rated by first 100 userIds.

In figure 2, we can see the change in mean rating, and the standard deviation (as errorbars) in ratings, for the first 100 userIds.
```{r usereffects3, echo=FALSE, fig.align = "center"}
user_counts[1:100,] %>% 
  ggplot(aes(x=userId, y=Mean_Rating)) + 
  geom_bar(stat="identity") + 
  geom_errorbar(aes(ymin = Mean_Rating-Standard_Deviation, ymax = Mean_Rating+Standard_Deviation)) +
  labs(title = "Mean Rating by User")+
  ylab("Mean Rating")

rm(user_counts, user_ratings)
```
Figure 2: Mean rating by first 100 userIds.

####Movie Effects

Movie ratings will also be impacted by the movie itself, as some movies are better than others. Table 2 shows the mean rating and standard deviation for the first 6 movieIds.
```{r movieeffects1, echo=FALSE}
head(edx %>% group_by(movieId) %>% summarise(Movies_Rated=n(), Mean_Rating=mean(rating), Standard_Deviation=sd(rating))
)
```
Table 2: Mean rating and standard deviation for the first 6 movieIds

Figure 3 visualizes the number of ratings for the first 100 movieIds
```{r movieeffects2, echo=FALSE, fig.align = "center"}
movie_counts = edx %>% group_by(movieId) %>% summarise(Movies_Rated=n(), Mean_Rating=mean(rating), Standard_Deviation = sd(rating))
movie_counts[1:100,] %>% 
  ggplot(aes(x=movieId, y=Movies_Rated)) + 
  geom_bar(stat="identity") + 
  labs(title = "Number of Ratings for Each Movie")+
  ylab("Number of Movies Rated")
```
Figure 3: Number of Movies rated by first 100 movieIds

In figure 4, we can see the change in mean rating, and the standard deviation (as errorbars) in ratings, for the first 100 movieIds
```{r movieeffects3, echo=FALSE, fig.align = "center"}
movie_counts[1:100,] %>% 
  ggplot(aes(x=movieId, y=Mean_Rating)) + 
  geom_bar(stat="identity") + 
  geom_errorbar(aes(ymin = Mean_Rating-Standard_Deviation, ymax = Mean_Rating+Standard_Deviation)) +
  labs(title = "Mean Rating by Movie") +
  ylab("Mean Rating")

rm(movie_counts, movie_ratings)
```
Figure 4: Mean rating by first 100 movieIds

####Genre Relationships

Movie ratings may be impacted by the genre of the movies. However, each movie may belong to multiple genres. To see if there was a correlation between the genres, I did a Pearson-r correlation on the genre matrix. The correlations are visualized in Figure 5.

```{r genreeffects1, echo=FALSE, fig.align = "center"}
genre_matrix = edx[,c(7:24)]
cor_t = rcorr(as.matrix(genre_matrix), type="pearson")
cor_t_r = cor_t$r
corrplot(cor_t_r, method = "color", type = "upper")
```
Figure 5: Significance of correlation between the genres

As we can see, the correlations are quite weak.

For correlation lower than -0.1975513 (mean-sd), we have Comedy-Drama, Horror-Drama, and Comedy-Thriller, meaning these genres overlap the least.

For correlation greater than 0.2929194 (mean + sd), we have Animation-Children, meaning these genres overlap the most.

####Genre Effects

Given the correlation of genres with ratings, movie ratings will also be impacted by the movie's genres. Table 3 shows the mean rating and standard deviation for each genre. Plotting correlation between ratings and genres, we see no major interactions (Figure 6) - none of the correlation coefficients exceed 0.2 in either direction. This suggests that individual genres do not have an impact on ratings.
```{r genreeffects2, echo=FALSE, fig.align = "center"}
rm(cor_t, cor_t_r)

genre_matrix = edx[,c(3,7:24)]
cor_t = rcorr(as.matrix(genre_matrix), type="pearson")

cor_t_r = cor_t$r
cor_t_r = as.data.frame(cor_t_r[-1,1])
cor_t_r$genre <- row.names(cor_t_r)
colnames(cor_t_r) <- c("coef","genre")

cor_t_r %>% 
  ggplot(aes(x=genre, y=coef)) + 
  geom_bar(stat = 'identity') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = "Coefficients of Correlation between Genre and Rating") +
  ylab("Coefficients")
```
Figure 6: Correlation between genres and ratings.

And plotting mean ratings for genre, we see bias by genres as well.
```{r genreeffects3, echo=FALSE}
rm(cor_t, cor_t_r)

genre_matrix = edx[,c(1,2,3,7:24)]

genre_counts = genre_matrix %>% 
  gather('genre', 'present', -c(userId, movieId, rating)) %>%
  filter(present == 1) %>% group_by(genre) %>%
  summarise(Movies_Rated = n(), Mean_Rating=mean(rating), Standard_Deviation=sd(rating))

genre_counts
```
Table 3: Mean rating and standard deviation for each genre.

Figure 7 visualizes the number of movies in each genre.
```{r genreeffects4, echo=FALSE, fig.align = "center"}
genre_counts %>% 
  ggplot(aes(x=genre, y=Movies_Rated)) + 
  geom_bar(stat="identity") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = "Number of Movies Rated in Each Genre")+
  ylab("Number of Movies Rated")
```
Figure 7: Number of Movies rated in each genre.

In figure 8, we can see the change in mean rating and the standard deviation (as errorbars) in ratings for all genres.
```{r genreeffects5, echo=FALSE, fig.align = "center"}
genre_counts %>% 
  ggplot(aes(x=genre, y=Mean_Rating)) + 
  geom_bar(stat="identity") + 
  geom_errorbar(aes(ymin = Mean_Rating-Standard_Deviation, ymax = Mean_Rating+Standard_Deviation)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = "Mean Rating by Genre")+
  ylab("Mean Rating")
```
Figure 8: Mean rating and standard deviation for all genres.

###Genre Combination

However, the combination of genres a movie falls into may be more important than the discrete genres it is part of. Figure 9 visualizes the mean rating by genre combination for 50 top-rated genre combinations.
```{r genrecombo1, echo=FALSE, fig.align = "center"}

genre_matrix = edx[,c(1,2,3,6:23)]

genre_matrix1 = genre_matrix %>% 
  gather('genre', 'present', -c(userId, movieId, rating)) %>%
  filter(present == 1) %>%
  select(-c(rating, present)) %>%
  group_by_at(vars(userId:movieId)) %>%
  summarize_all(paste, collapse="|")

genre_matrix2 = genre_matrix[,c(1,2,3)]

genre_matrix3 = genre_matrix1 %>% 
  left_join(genre_matrix2, by=c('userId', 'movieId'))

genre_matrix = genre_matrix1 %>% 
  left_join(genre_counts, by='genre')

genre_counts = edx %>% 
  group_by(genres) %>%
  summarise(Mean_Rating = mean(rating), Standard_Deviation = sd(rating))

genre_counts = arrange(genre_counts, desc(Mean_Rating))

genre_counts[1:50,] %>% 
  ggplot(aes(x=genres, y=Mean_Rating)) + 
  geom_bar(stat="identity") + 
  geom_errorbar(aes(ymin = Mean_Rating-Standard_Deviation, ymax = Mean_Rating+Standard_Deviation)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = "Mean Rating for Top 50 Genres")+
  ylab("Mean Rating")

rm(genre_matrix1, genre_matrix2, genre_matrix3)
```
Figure 9: Mean Rating by genre combination for 50 top-rated genre combinations.

In Figure 10 we see the distribution for the 50 least rated genre combinations
```{r genrecombo2, echo=FALSE, fig.align = "center"}
genre_counts[(nrow(genre_counts)-50):nrow(genre_counts),] %>% 
  ggplot(aes(x=genres, y=Mean_Rating)) + 
  geom_bar(stat="identity") + 
  geom_errorbar(aes(ymin = Mean_Rating-Standard_Deviation, ymax = Mean_Rating+Standard_Deviation)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = "Mean Rating for Bottom 50 Genres")+
  ylab("Mean Rating")

```
Figure 10: Mean Rating by genre combination for 50 least-rated genre combinations.

Correlating the genre combinations with ratings, we see
```{r genrecombo3, echo=FALSE, fig.align = "center"}
edx = edx %>% 
  left_join(genre_matrix[,1:3], by=c('userId', 'movieId'))

genre_corplot = edx[,c(3,27)]

genre_corplot  = genre_corplot %>% 
  mutate(present = 1) %>%
  group_by_at(vars(-present)) %>%  # group by everything other than the value column. 
  mutate(row_id=1:n()) %>% ungroup() %>%  # build group index
  spread(key=genre, value=present, fill=0) %>%    # spread
  select(-row_id)  # drop the index

cor_t = rcorr(as.matrix(genre_corplot), type="pearson")

cor_t_p = cor_t$P

heatmap(cor_t_p, Rowv = NA, Colv = NA)

```
Figure 11: Correlation of Genre Combination with Ratings.

Of the `r nrow(genre_counts)` unique genre combinations, `r sum(cor_t_p[1,]< 0.05, na.rm = TRUE)` of them were significantly correlating with ratings. This suggests a much stronger relationship between genre combinations and rating. Therefore, I will use genre bias from the genre combinations in the regression.

```{r genresig1, echo=FALSE}
rm(cor_t, cor_t_p, genre_corplot, genre_matrix, genre_counts)
```
####Year of Release Effects

The year of a movie's release may affect ratings as well. Old movies may be rated more highly because they are considered classics. On the other hand, there will also be fewer movies in the early years, which could lead to the ratings having higher variance. Table 4 shows the mean rating and standard deviation for the first 10 movieIds.
```{r year1, echo=FALSE}
head(edx %>% group_by(year) %>% summarise(Number_of_Ratings=n(), Mean_Rating=mean(rating), SD_Rating=sd(rating))
)
```
Table 4: Mean rating and standard deviation for movies by Year

Figure 12 visualizes the number of movies rated for each year of release.
```{r year2, echo=FALSE, fig.align = "center"}
year_counts = edx %>% group_by(year) %>% summarise(Movies_Rated=n(), Mean_Rating=mean(rating), Standard_Deviation = sd(rating))
year_counts %>% 
  ggplot(aes(x=year, y=Movies_Rated)) + 
  geom_bar(stat="identity") + 
  labs(title = "Number of Movies Rated from Each Year")+
  ylab("Number of Movies Rated")
```
Figure 12: Number of Movies rated for each year of release.

In figure 13, we can see the change in mean rating, and the standard deviation (as errorbars) in ratings, for each year of rellease.
```{r year3, echo=FALSE, fig.align = "center"}
year_counts %>% 
  ggplot(aes(x=year, y=Mean_Rating)) + 
  geom_bar(stat="identity") + 
  geom_errorbar(aes(ymin = Mean_Rating-Standard_Deviation, ymax = Mean_Rating+Standard_Deviation)) +
  labs(title = "Mean Rating by Year")+
  ylab("Mean Rating")
```
Figure 13: Mean rating by first 1000 userIds.

####Time of Rating Effects

Are ratings affected by the year of rating? Table 5 shows the mean rating and standard deviation for the first 6 years.
```{r timestamp1, echo=FALSE}
rm(year_counts)

head(edx %>% group_by(rating_datetime) %>% summarise(Movies_Rated=n(), Mean_Rating=mean(rating), SD_Rating=sd(rating))
)
```
Table 5: Mean rating and standard deviation for the first 6 years of rating

Figure 14 visualizes the number of ratings for each year of rating.
```{r timestamp2, echo=FALSE, fig.align = "center"}
rating_datetime_counts = edx %>% group_by(rating_datetime) %>% 
  summarise(Movies_Rated=n(), Mean_Rating=mean(rating), Standard_Deviation=sd(rating))
rating_datetime_counts %>% 
  ggplot(aes(x=rating_datetime, y=Movies_Rated)) + 
  geom_bar(stat="identity") + 
  labs(title = "Number of Movies Rated Each Year")+
  ylab("Number of Movies Rated")
```
Figure 14: Number of Movies rated Year of Rating.

In figure 15, we can see the change in mean rating, and the standard deviation (as errorbars) in ratings, for each year of rating.
```{r timestamp3, echo=FALSE, fig.align = "center"}
rating_datetime_counts %>% 
  ggplot(aes(x=rating_datetime, y=Mean_Rating)) + 
  geom_bar(stat="identity") + 
  geom_errorbar(aes(ymin = Mean_Rating-Standard_Deviation, ymax = Mean_Rating+Standard_Deviation)) +
  labs(title = "Mean Rating by Rating Year")+
  ylab("Mean Rating")
```
Figure 15: Mean rating by Year of Rating.

The figures who little impact of year. Digging in deeper, I created another variable - distance_from_release - that calculated how long after the release of a movie was it rated by a user. Plotting the mean and standard deviation for this, we see similar plateauing (Figure 16).
```{r timestamp4, echo=FALSE, fig.align = "center"}
rating_year_distance = edx %>% mutate(distance_from_release = rating_datetime - year) %>%
  group_by(distance_from_release) %>% 
  summarise(Movies_Rated=n(), Mean_Rating=mean(rating), Standard_Deviation=sd(rating))
rating_year_distance %>% 
  ggplot(aes(x=distance_from_release, y=Mean_Rating)) + 
  geom_bar(stat="identity") + 
  geom_errorbar(aes(ymin = Mean_Rating-Standard_Deviation, ymax = Mean_Rating+Standard_Deviation)) +
  labs(title = "Mean Rating by Distance of Year of Rating from Year of Release")+
  ylab("Mean Rating")
```
Figure 15: Mean rating by Distance of Year of Rating from Year of Release.

```{r cleanup, echo=FALSE, include=FALSE}
rm(rating_datetime_counts, rating_year_distance)
```
##Results

My analysis plan was to test the regression with each variable, and then to combine the most successful variables. I then planned to run this combination model with standardization and regularization.

###Regressions Accounting for Movie Bias

My first variable was the movie itself - we know some movies are better than others, so it would follow that ratings for movies would be biased by the movie.
```{r b_i, echo=FALSE}
mu = mean(edx$rating)

movie_avgs <- edx %>% 
  group_by(movieId) %>% 
  summarise(b_i = mean(rating - mu))

pred_movie <- validation %>% 
  left_join(movie_avgs,by='movieId') %>% 
  mutate(pred = mu + b_i) %>%
  .$pred

movie_error <- RMSE(pred_movie,validation$rating)

rm(movie_avgs, pred_movie)
```

The resulting model had an RMSE of `r movie_error`.

###Regressions Accounting for User Bias

My next variable was the user themselves - we know that we have different tastes in movies, and are therefore likely to rate certain movies better than others.
```{r b_u, echo=FALSE}
user_avgs <- edx %>% 
  group_by(userId) %>% 
  summarise(b_u = mean(rating - mu))

pred_user <- validation %>% 
  left_join(user_avgs,by='userId') %>% 
  mutate(pred = mu + b_u) %>%
  .$pred

user_error <- RMSE(pred_user,validation$rating)

rm(user_avgs, pred_user)
```

The resulting model had an RMSE of `r user_error`.

###Regressions Accounting for Genre Bias

```{r b_g, echo=FALSE}
genre_avgs <- edx %>% 
  group_by(genres) %>% 
  summarise(b_g = mean(rating - mu))

pred_genre <- validation %>% 
  left_join(genre_avgs,by='genres') %>% 
  mutate(pred = mu + b_g) %>%
  .$pred

genre_error <- RMSE(pred_genre,validation$rating, na.rm=TRUE)

rm(genre_avgs, pred_genre)
```

###Regressions Accounting for Year Bias

```{r b_y, echo=FALSE}
year_avgs <- edx %>% 
  group_by(year) %>% 
  summarise(b_y = mean(rating - mu))

pred_year <- validation %>% 
  mutate(year = as.numeric(substr(substrR(substrR(validation$title, 6),5),1,4))) %>%
  left_join(year_avgs,by='year') %>% 
  mutate(pred = mu + b_y) %>%
  .$pred

year_error <- RMSE(pred_year,validation$rating)

rm(year_avgs, pred_year)
```

The resulting model had an RMSE of `r year_error`.

###Regressions Accounting for Time Bias

```{r b_t, echo=FALSE}
time_avgs <- edx %>% 
  group_by(rating_datetime) %>% 
  summarise(b_t = mean(rating - mu))

pred_time <- validation %>% 
  mutate(rating_datetime = year(as_datetime(timestamp))) %>%
  left_join(time_avgs,by='rating_datetime') %>% 
  mutate(pred = mu + b_t) %>%
  .$pred

time_error <- RMSE(pred_time,validation$rating)

rm(time_avgs, pred_time)
```

The resulting model had an RMSE of `r time_error`.

###Regressions Accounting for Distance between Year of Release and Year of Rating Bias

```{r b_y_t, echo=FALSE}
edx = edx %>% 
  mutate(distance_from_release = rating_datetime - year)

year_time_avgs <- edx %>% 
  group_by(distance_from_release) %>% 
  summarise(b_y_t = mean(rating - mu))

pred_year_time <- validation %>% 
  mutate(year = as.numeric(substr(substrR(substrR(validation$title, 6),5),1,4))) %>%
  mutate(rating_datetime = year(as_datetime(timestamp))) %>%
  mutate(distance_from_release = rating_datetime - year) %>%
  left_join(year_time_avgs,by='distance_from_release') %>% 
  mutate(pred = mu + b_y_t) %>%
  .$pred

year_time_error <- RMSE(pred_year_time,validation$rating)

rm(year_time_avgs, pred_year_time)
```

The resulting model had an RMSE of `r year_time_error`.

The best models were the ones that took into account movie bias, user bias, and genre bias.

###Regressions Combining Movie and User Bias

Of all the variables that impact ratings, movie bias and user bias are the most essential. Therefore, I added these to our regression model
```{r b_i_u, echo=FALSE}
movie_avgs <- edx %>% 
  group_by(movieId) %>% 
  summarise(b_i = mean(rating - mu, na.rm = TRUE))

user_avgs <- edx %>% 
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>% 
  summarise(b_u = mean(rating - mu - b_i, na.rm = TRUE))

pred_um_combo <- validation %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  mutate(pred = rowSums(as.matrix(mu + b_i + b_u), na.rm=TRUE)) %>%
  .$pred

um_combo_error <- RMSE(pred_um_combo,validation$rating)

rm(movie_avgs, user_avgs, pred_um_combo)
```

The resulting model had an RMSE of `r um_combo_error`.

###Regressions Combining Movie, User and Genre Bias
```{r b_i_u_g, echo=FALSE}
movie_avgs <- edx %>% 
  group_by(movieId) %>% 
  summarise(b_i = mean(rating - mu, na.rm = TRUE))

user_avgs <- edx %>% 
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>% 
  summarise(b_u = mean(rating - mu - b_i, na.rm = TRUE))

genre_avgs <- edx %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  group_by(genres) %>% 
  summarise(b_g = mean(rating - mu - b_i - b_u, na.rm = TRUE))

pred_umg_combo <- validation %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  left_join(genre_avgs, by='genres') %>%
  mutate(pred = rowSums(as.matrix(mu + b_i + b_u + b_g), na.rm=TRUE)) %>%
  .$pred

umg_combo_error <- RMSE(pred_umg_combo,validation$rating)

rm(movie_avgs, user_avgs, genre_avgs, pred_umg_combo)
```

Adding genre to the mix, we see the RMSE worsen to `r umg_combo_error`.

###Regressions Combining Movie, User and Year of Release Bias
```{r b_i_u_y, echo=FALSE}
movie_avgs <- edx %>% 
  group_by(movieId) %>% 
  summarise(b_i = mean(rating - mu, na.rm = TRUE))

user_avgs <- edx %>% 
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>% 
  summarise(b_u = mean(rating - mu - b_i, na.rm = TRUE))

year_avgs <- edx %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  group_by(year) %>% 
  summarise(b_y = mean(rating - mu - b_i - b_u, na.rm = TRUE))

pred_umy_combo <- validation %>% 
  mutate(year = as.numeric(substr(substrR(substrR(validation$title, 6),5),1,4))) %>%
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  left_join(year_avgs, by='year') %>%
  mutate(pred = rowSums(as.matrix(mu + b_i + b_u + b_y), na.rm=TRUE)) %>%
  .$pred

umy_combo_error <- RMSE(pred_umy_combo,validation$rating)

rm(movie_avgs, user_avgs, year_avgs, pred_umy_combo)
```

So we took out genre and added year of release to the mix, and we saw the RMSE better to `r umy_combo_error`.

###Regressions Combining Movie, User and Time of Rating Bias
```{r b_i_u_t, echo=FALSE}
movie_avgs <- edx %>% 
  group_by(movieId) %>% 
  summarise(b_i = mean(rating - mu, na.rm = TRUE))

user_avgs <- edx %>% 
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>% 
  summarise(b_u = mean(rating - mu - b_i, na.rm = TRUE))

time_avgs <- edx %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  group_by(rating_datetime) %>% 
  summarise(b_t = mean(rating - mu - b_i - b_u, na.rm = TRUE))

pred_umt_combo <- validation %>% 
  mutate(rating_datetime = year(as_datetime(timestamp))) %>%
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  left_join(time_avgs, by='rating_datetime') %>%
  mutate(pred = rowSums(as.matrix(mu + b_i + b_u + b_t), na.rm=TRUE)) %>%
  .$pred

umt_combo_error <- RMSE(pred_umt_combo,validation$rating)

rm(movie_avgs, user_avgs, time_avgs, pred_umt_combo)
```

So we took out genre and added year of release to the mix, and we saw the RMSE better to `r umt_combo_error`.

###Regressions Combining Movie, User and Difference between Time of Rating and Year of Release Bias
```{r b_i_u_y_t, echo=FALSE}
movie_avgs <- edx %>% 
  group_by(movieId) %>% 
  summarise(b_i = mean(rating - mu, na.rm = TRUE))

user_avgs <- edx %>% 
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>% 
  summarise(b_u = mean(rating - mu - b_i, na.rm = TRUE))

year_time_avgs <- edx %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  group_by(distance_from_release) %>% 
  summarise(b_y_t = mean(rating - mu - b_i - b_u, na.rm = TRUE))

pred_umyt_combo <- validation %>% 
  mutate(year = as.numeric(substr(substrR(substrR(validation$title, 6),5),1,4))) %>%
  mutate(rating_datetime = year(as_datetime(timestamp))) %>%
  mutate(distance_from_release = rating_datetime - year) %>%
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  left_join(year_time_avgs,by='distance_from_release') %>% 
  mutate(pred = rowSums(as.matrix(mu + b_i + b_u + b_y_t), na.rm=TRUE)) %>%
  .$pred

umyt_combo_error <- RMSE(pred_umyt_combo,validation$rating)

rm(movie_avgs, user_avgs, year_time_avgs, pred_umyt_combo)
```

This was the most successful model so far, and the RMSE bettered to `r umyt_combo_error`. Therefore I decided to use only this model for standardization and regularization tests.

###Regressions with Standardization

What happens if we standardize ratings within users and movies, such that ratings by each user fell on a normal curve, as did ratings for each movie?
```{r b_s, echo=FALSE}

a = unique(edx$userId)

edx = edx %>% mutate(scaled_rating_user = unlist(lapply(a, function(a){
  normalize(edx$rating[which(edx$userId == a)], method = "range", range = c(0, 5))
})))

edx = edx[order(edx$movieId),]
b = unique(edx$movieId)

edx = edx %>% mutate(scaled_rating_movie = unlist(lapply(b, function(b){
  normalize(edx$rating[which(edx$movieId == b)], method = "range", range = c(0, 5))
})))

edx = edx[order(edx$distance_from_release),]
c = unique(edx$distance_from_release)

edx = edx %>% mutate(scaled_rating_year = unlist(lapply(c, function(c){
  normalize(edx$rating[which(edx$distance_from_release == c)], method = "range", range = c(0, 5))
})))

mu_user = mean(edx$scaled_rating_user, na.rm = TRUE)
mu_movie = mean(edx$scaled_rating_movie, na.rm = TRUE)
mu_year = mean(edx$scaled_rating_year, na.rm = TRUE)

movie_avgs <- edx %>% 
  group_by(movieId) %>% 
  summarise(b_i = mean(scaled_rating_movie - mu_movie, na.rm = TRUE))

user_avgs <- edx %>% 
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>% 
  summarise(b_u = mean(scaled_rating_user - mu_user - b_i, na.rm = TRUE))

year_time_avgs <- edx %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  group_by(distance_from_release) %>% 
  summarise(b_y_t = mean(scaled_rating_year - mu_year - b_i - b_u, na.rm = TRUE))

pred_umyt_combo <- validation %>% 
  mutate(year = as.numeric(substr(substrR(substrR(validation$title, 6),5),1,4))) %>%
  mutate(rating_datetime = year(as_datetime(timestamp))) %>%
  mutate(distance_from_release = rating_datetime - year) %>%
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  left_join(year_time_avgs,by='distance_from_release') %>% 
  mutate(pred = rowSums(as.matrix(mu + b_i + b_u + b_y_t), na.rm=TRUE)) %>%
  .$pred

s_error <- RMSE(pred_umyt_combo,validation$rating)

rm(movie_avgs, user_avgs, year_time_avgs, pred_umyt_combo, a, b, c)
```

The RMSE with standardization of ratings was quite high. One explanation can be that standardization is not helpful for predicting real ratings because real ratings are not standardized. However, for modeling movie recommendations (i.e., categorical recommendations), standardization may be helpful.

###Regressions with Regularization

We then checked the RMSE with regularization. When keeping year in the mix, the RMSE did not improve with regularization (Figure 16).
```{r b_l, echo=FALSE}

lambda_reg <- seq(0,10,0.25)

pred_umyt_combo_rmses = sapply(lambda_reg,function(l){
  mu_r = mean(edx$rating)
  
  movie_avgs_reg <- edx %>% 
    group_by(movieId) %>% 
    summarise(b_i_r = sum(rating - mu_r, na.rm = TRUE)/(n()+l))

  user_avgs_reg <- edx %>% 
    left_join(movie_avgs_reg, by='movieId') %>%
    group_by(userId) %>% 
    summarise(b_u_r = sum(rating - mu_r - b_i_r, na.rm = TRUE)/(n()+l))

  year_time_avgs_reg <- edx %>% 
    left_join(movie_avgs_reg, by='movieId') %>%
    left_join(user_avgs_reg, by='userId') %>%
    group_by(distance_from_release) %>% 
    summarise(b_y_t_r = sum(rating - mu_r - b_i_r - b_u_r, na.rm = TRUE)/(n()+l))

  pred_umyt_combo_reg <- validation %>% 
    mutate(year = as.numeric(substr(substrR(substrR(validation$title, 6),5),1,4))) %>%
    mutate(rating_datetime = year(as_datetime(timestamp))) %>%
    mutate(distance_from_release = rating_datetime - year) %>%
    left_join(movie_avgs_reg, by='movieId') %>%
    left_join(user_avgs_reg, by='userId') %>%
    left_join(year_time_avgs_reg,by='distance_from_release') %>% 
    mutate(pred = rowSums(as.matrix(mu_r + b_i_r + b_u_r + b_y_t_r), na.rm=TRUE)) %>%
    .$pred
  
  return(RMSE(pred_umyt_combo_reg,validation$rating))
})

qplot(lambda_reg, pred_umyt_combo_rmses)  

```
Figure 16: RMSE at different lambdas for the User-Movie-Distance between Year of Rating and Release Model.

```{r}
r_error = pred_umyt_combo_rmses[which.min(pred_umyt_combo_rmses)]
r_error_lambda = lambda_reg[which.min(pred_umyt_combo_rmses)]

rm(pred_umyt_combo_rmses)
```
The best RMSE was `r r_error` at a lambda value of `r r_error_lambda`. Therefore, regularization improved the combined user-movie-distance-from-release model's predictive ability.

###RMSE Table

All RMSEs are listed in table 6.
```{r rmse, echo=FALSE}
RMSE_table = data.frame(model = c('Movie Bias', 'User Bias', 'Genre Bias', 'Time Bias', 'Year Bias', 'Year of Release vs Time of Rating bias', 'User-Movie Combo', 'User-Movie-Genre Combo', 'User-Movie-Year of Release Combo',  'User-Movie-Time of Rating Combo', 'User-Movie-Distance from Release Combo', 'Standardization', 'Regularization'), RMSE = c(movie_error, user_error, genre_error, time_error, year_error, year_time_error, um_combo_error, umg_combo_error, umy_combo_error, umt_combo_error, umyt_combo_error, s_error, r_error))

RMSE_table = RMSE_table[order(RMSE_table$RMSE),]

RMSE_table
```
Table 6: RMSEs across all models from lowest RMSE to highest RMSE.

##Conclusion

I conclude that movie, user and distance from release are the best predictors of ratings. By predicting ratings, we can effectively and successfully predict target audience of a movie as well as movie recommendations for a viewer.
